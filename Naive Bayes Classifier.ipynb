{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Author of Question: Kimia Noorbakhsh\n",
    "\t\t\t<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to implement a Naive Bayes Classifier for the MNIST Dataset (Well, of course, **from scratch**!). The MNIST data set is a vast database of handwritten digits that is commonly used to form various image processing systems. \n",
    "\n",
    "Please note the following before you continue:\n",
    "- After implementing your Classifier, train your model on the **train** section of the MNIST dataset and validate your model by testing it on the test set.\n",
    "- Note that if you use any of the **test** images during training or for improving the accuracy, you will not earn any points for this assignment. \n",
    "- Do not forget to use **Laplace Smoothing** to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Bayes rule:\n",
    "    $$P(c|x) =  \\frac{P(x|c)P(c)}{P(x)} \\;\\;\\;\\;(1)$$\n",
    "    \n",
    "Here $x$ stands for the image, or more precisely, the pixel values of the formatted image as a vector, and $c$ stands for the number, which can be 0, 1, ..., 9. We can read the left side $P(c|x)$ as \"the probability of the class being $c$ given the $x$\" data (posterior). We can read the right side $P(x|c)$ as \"the probability of $x$ data being in the $c$\" class (likelihood). We care about the value of $c$. It tells us \"what number\" this picture is. The chosen class is simply the one with the highest probability for this data:\n",
    "$$c^* = argmax_{c}P(c|x)$$\n",
    "Now, we can ignore $P(x)$ in equation (1) (why?). Using this information, we can simplify our problem so that, in order to choose \"which digit\" given an image, all we need to do is calculate this argmax (P(x) is removed):\n",
    "$$c^* = argmax_{c}P(x|c)P(c)$$\n",
    "Now, we need to think about how to calculate $P(c)$, and $P(x|c)$. We leave this section for you to think about ^_^. But as a guide for $P(x|c)$, read the following. \n",
    "\n",
    "Remember that pixels represent the intensity of light, and that the intensity of light is in fact continuous. A first reasonable estimation to model continuous data is the multivariate Gaussian or multivariate Normal. We can write:\n",
    "$$P(x|c) = \\frac{1}{\\sqrt{(2\\pi)^{D}|\\Sigma|}}\\exp(-\\frac{1}{2}(x - \\mu)^{T}\\Sigma^{-1}(x-\\mu))$$\n",
    "Note that because probabilities are very small when dimensionality is high, we are going to work with log-probability rather than probability. So instead of getting numbers that are very close to 0, which is inaccurate when you use a computer to represent them, we're just going to get negative numbers. The log-probability can be represented as ($D$ is the dimentionality):\n",
    "$$\\log{P(x|c) = -\\frac{D}{2}\\ln(2\\pi)-\\frac{1}{2}\\ln|\\Sigma|-\\frac{1}{2}(x - \\mu)^{T}\\Sigma^{-1}(x-\\mu)}$$\n",
    "To calculate $\\mu$ and $\\Sigma$, you can use the **sample** mean and covariance (see [here.](https://en.wikipedia.org/wiki/Sample_mean_and_covariance)) Also note that to get the argmax over $P(x|c)P(c)$, we can choose the digit class using:\n",
    "$$c^* = argmax_{c}(\\log P(x|c)+\\log P(c))$$\n",
    "Now, let's dive into implementing a **Gaussian Naive Bayes Classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collectable": true
   },
   "source": [
    "For your convineince, use the following cells to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\mahdi\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\mahdi\\anaconda3\\lib\\site-packages (from torchvision) (6.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mahdi\\anaconda3\\lib\\site-packages (from torchvision) (1.16.4)\n",
      "Requirement already satisfied: torch==1.10.1 in c:\\users\\mahdi\\anaconda3\\lib\\site-packages (from torchvision) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mahdi\\anaconda3\\lib\\site-packages (from torch==1.10.1->torchvision) (4.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mahdi\\anaconda3\\lib\\site-packages (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "# and other libraries you might need\n",
    "\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('./data', train=True, download=True)\n",
    "test_data  = datasets.MNIST('./data', train=False, download=True)\n",
    "\n",
    "train_images = np.array(train_data.data)\n",
    "train_labels = np.array(train_data.targets)\n",
    "test_images = np.array(test_data.data)\n",
    "test_labels = np.array(test_data.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes:\n",
    "    def train(self, train_images, train_labels):\n",
    "        # Put your Code here. (30 Points)\n",
    "        self.labels = set(train_labels)\n",
    "        flatten_train_images = train_images.reshape(len(train_images), -1)\n",
    "        self.means = {c: self.sample_mean(flatten_train_images, train_labels, c) for c in self.labels}\n",
    "        self.covs = {}\n",
    "        self.label_pros = {}\n",
    "        self.smoothing = 1\n",
    "        best_accuracy = 0\n",
    "        smoothings_test = [1, 10, 100, 500, 1000, 2000, 3000, 4000, 5000, 10000]\n",
    "        for smoothing in smoothings_test:\n",
    "            means = {c: self.sample_mean(flatten_train_images, train_labels, c, smoothing) for c in self.labels}\n",
    "            label_pros = self.calculate_log_p_c(train_labels, smoothing)\n",
    "            sampled_covs = {c: self.sample_cov(flatten_train_images, train_labels, c, smoothing) for c in\n",
    "                            self.labels}\n",
    "            accuracy = self.calc_accuracy(flatten_train_images, train_labels, label_pros, means, sampled_covs)\n",
    "            print(f'Accuracy on test data with smoothing {smoothing} : {accuracy * 100} %')\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                self.smoothing = smoothing\n",
    "                self.covs = sampled_covs\n",
    "                self.label_pros = label_pros\n",
    "                self.means = means\n",
    "        print(f'Selected smoothing {self.smoothing}')\n",
    "\n",
    "    def calc_accuracy(self, images, labels, label_pros=None, means=None, covs=None):\n",
    "        # Put your Code here. (5 Points)\n",
    "        flatten_train_images = images.reshape(len(images), -1)\n",
    "        label_pros = label_pros or self.label_pros\n",
    "        means = means or self.means\n",
    "        covs = covs or self.covs\n",
    "        number_of_corrects = 0\n",
    "        predicts = self.predict_labels(flatten_train_images, label_pros, means, covs)\n",
    "        for predicted, label in zip(predicts, labels):\n",
    "            if predicted == label:\n",
    "                number_of_corrects += 1\n",
    "        return number_of_corrects / len(images)\n",
    "\n",
    "    def predict_labels(self, images, label_pros, means, covs):\n",
    "        # Put your Code here. (5 Points)\n",
    "        logpdf = {c: multivariate_normal.logpdf(images, mean=means[c], cov=covs[c]) for c in self.labels}\n",
    "        predicts = []\n",
    "        for i in range(len(images)):\n",
    "            best_label = None\n",
    "            best_prob = None\n",
    "            for c in self.labels:\n",
    "                log_p_x_given_c = logpdf[c][i]\n",
    "                if (best_prob is None) or ((log_p_x_given_c + label_pros[c]) > best_prob):\n",
    "                    best_prob = log_p_x_given_c + label_pros[c]\n",
    "                    best_label = c\n",
    "            predicts.append(best_label)\n",
    "        return predicts\n",
    "\n",
    "    def sample_mean(self, data, train_labels, c, smoothing_parameter=0):\n",
    "        _sum = np.zeros_like(data[0])\n",
    "        _length = smoothing_parameter\n",
    "        for img, label in zip(data, train_labels):\n",
    "            if label == c:\n",
    "                _sum += img\n",
    "                _length += 1\n",
    "        return _sum / _length\n",
    "\n",
    "    def sample_cov_with_assume_independence(self, data, train_labels, c, smoothing_parameter=0):\n",
    "        features_size = len(data[0])\n",
    "        matrix = np.zeros((features_size, features_size))\n",
    "        data_with_this_class = np.array([img for img, label in zip(data, train_labels) if label == c])\n",
    "        for i in range(features_size):\n",
    "            matrix[i][i] = np.cov(data_with_this_class[:, i]) + smoothing_parameter\n",
    "        return matrix\n",
    "\n",
    "    def sample_cov(self, data, train_labels, c, smoothing_parameter=0):\n",
    "        # because without independence assumption result and accuracy is better we use it\n",
    "        features_size = len(data[0])\n",
    "        data_with_this_class = np.array([img for img, label in zip(data, train_labels) if label == c])\n",
    "        matrix = np.cov(data_with_this_class.transpose())\n",
    "        return matrix + (np.eye(features_size) * smoothing_parameter)\n",
    "\n",
    "    def calculate_log_p_c(self, train_labels, smoothing_parameter=0):\n",
    "        p_c_map = {_: 0 for _ in range(10)}\n",
    "        for item in train_labels:\n",
    "            p_c_map[item] += 1\n",
    "        for k, v in p_c_map.items():\n",
    "            p_c_map[k] = np.log((v + smoothing_parameter) / (\n",
    "                    len(train_labels) + smoothing_parameter * len(p_c_map)))  # laplace smoothing\n",
    "        return p_c_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data with smoothing 1 : 86.61999999999999 %\n",
      "Accuracy on test data with smoothing 10 : 90.125 %\n",
      "Accuracy on test data with smoothing 100 : 93.50166666666667 %\n",
      "Accuracy on test data with smoothing 500 : 95.15 %\n",
      "Accuracy on test data with smoothing 1000 : 95.56666666666666 %\n",
      "Accuracy on test data with smoothing 2000 : 95.78333333333333 %\n",
      "Accuracy on test data with smoothing 3000 : 95.72666666666667 %\n",
      "Accuracy on test data with smoothing 4000 : 95.59 %\n",
      "Accuracy on test data with smoothing 5000 : 95.435 %\n",
      "Accuracy on test data with smoothing 10000 : 94.54833333333333 %\n",
      "Selected smoothing 2000\n"
     ]
    }
   ],
   "source": [
    "network = Bayes()\n",
    "network.train(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data (%) : 95.19\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data (%) : \" + str(network.calc_accuracy(test_images, test_labels) * 100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f336af7d54ba0f0c1daaf2256eb85f31e983e88153daf7a27ef3ea6c724faba4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
